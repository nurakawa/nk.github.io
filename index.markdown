---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: page
title: null
---


![My Picture](assets/photo-nura.jpg){: style="float: right; display:block; margin-left:auto; margin-right:auto; height: 200px; border-radius: 50%; padding: 5px;"}

# about 

My name is Nura Kawa, and I am a Research Scientist at [neurocat](https://neurocat.ai), a startup based in Berlin, Germany.
	
My research interests are in Robustness and Explainability of AI. I would like to explore methods that enable the development of AI applications that are highly functional, but also reliable and responsible. At neurocat I currently work on developing and implementing methods for assessing the robustness of AI for on autonomous vehicles. 
 

Previously I completed an MSc in Statistics from KU Leuven (Belgium), during which I wrote my [Master's Thesis](https://github.com/nurakawa/localized-classmap/blob/main/msc_thesis_kawa.pdf) on a new method for Explainable AI; during my studies I was fortunate to be funded by the [Science@Leuven Scholarship](https://wet.kuleuven.be/english/scienceatleuvenscholarship).  I also hold a BA in Statistics from UC Berkeley (USA), where I worked on research in Bayesian Statistics applied to Hydrogeology.

[LinkedIn](https://linkedin.com/in/nurakawa) - 
[GitHub](https://github.com/nurakawa)

# projects

- [BerDiBa (Berlin Digital Rail Operations)](https://www.hhi.fraunhofer.de/en/departments/ai/projects/berdiba.html) BerDiBa aims to implement a holistic digital twin for rail operations using innovative signal processing methods and Artificial Intelligence. My work focuses on methods for robustness assessment of AI modules in autonomous railway systems. 

- [Security of AI Systems](https://www.bsi.bund.de/DE/Service-Navi/Publikationen/Studien/Projekt_P464/Projekt_P464_node.html) An in-depth study on the security risks of transfer learning, including backdoor and adversarial attacks; in collaboration with the German Federal Office of Information Security [(BSI)](https://www.bsi.bund.de/DE/Service-Navi/Publikationen/Studien/Projekt_P464/Projekt_P464_node.html)

- [Localized Classmaps](https://github.com/nurakawa/localized-classmap) A new Explainable AI method that enables an interpretation of the outputs of classification algorithms.


# publications

Artificial Intelligence:

- (2022) [Security of AI-Systems: Fundamentals - Adversarial Deep Learning](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/Security-of-AI-systems_fundamentals.pdf?__blob=publicationFile&v=4) Bundesamt für Sicherheit in der Informationstechnik.


Bayesian Statistics for Hydrogeology:

- (2022) [Defining Hydrogeological Site Similarity with Hierarchical Agglomerative Clustering](https://doi.org/10.1111/gwat.13261). _Groundwater_. __Kawa, N.__, Cucchi, K., Rubin, Y., Attinger, S. and Heße, F. 

- (2021) [exPrior: An R Package for the Formulation of Ex-Situ Priors.](https://journal.r-project.org/archive/2021/RJ-2021-031/index.html) _The RJournal_. Falk Heße, Karina Cucchi, __Nura Kawa__ and Yoram Rubin.

- (2019) [Ex-situ priors: A Bayesian hierarchical framework for defining informative prior distributions in hydrogeology](https://doi.org/10.1016/j.advwatres.2019.02.003). _Advances in Water Resources_. Cucchi, K., Heße, F., __Kawa, N.__, Wang, C., & Rubin, Y. 

# etc
- My [talk](https://www.youtube.com/watch?v=l-YJm6Umz2s) at PyData Yerevan 2022 called "The Explainability Problem: Towards Understanding AI"
- I occasionally write on [Medium](https://medium.com/@nurakawa)
